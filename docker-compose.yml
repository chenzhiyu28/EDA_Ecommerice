version: '3.8' # 指定 docker-compose 文件格式的版本

services: # 定义组成应用的所有容器服务

  # 用户数据库服务
  user-db:
    image: mongo:latest # 使用官方最新的 MongoDB 镜像
    container_name: user-db # 给容器起个名字，方便识别
    volumes: # 数据持久化，将容器内的 /data/db 映射到本地的 user-mongo-data 卷
      - user-mongo-data:/data/db
    networks: # 将容器连接到内部网络 my_network
      - my_network
    restart: unless-stopped # 除非手动停止，否则容器挂掉后自动重启

  # 订单数据库服务
  order-db:
    image: mongo:latest
    container_name: order-db
    volumes:
      - order-mongo-data:/data/db
    networks:
      - my_network
    restart: unless-stopped

  # 用户服务
  user-service:
    container_name: user-service
    build: # 指定如何构建这个服务的镜像
      context: ./user-service # Dockerfile 所在的目录（相对 docker-compose.yml）
      dockerfile: Dockerfile # Dockerfile 的文件名
    ports: # 端口映射 <主机端口>:<容器端口>
      - "3000:3000" # 将你本地的 3000 端口映射到容器的 3000 端口
    environment: # 设置容器内的环境变量
      # 注意：这里的值会覆盖服务代码中 dotenv 加载的值
      - PORT=3000 #
      - MONGODB_URL=mongodb://user-db:27017/user-service # 指向 user-db 容器
      - NODE_ENV=development #
    depends_on: # 依赖关系，确保 user-db 先启动
      user-db: # Keep dependency on database
        condition: service_started # Default condition, wait for container start
      kafka: # Add dependency on kafka
        condition: service_healthy # Wait for kafka's healthcheck to pass
    networks:
      - my_network
    restart: unless-stopped

  # 订单服务
  order-service:

    container_name: order-service
    build:
      context: ./order-service
      dockerfile: Dockerfile
    ports:
      - "3001:3001" #
    environment:
      - PORT=3001 #
      - MONGODB_URL=mongodb://order-db:27017/order-service # 指向 order-db 容器
      - NODE_ENV=development #
    depends_on:
      order-db:
        condition: service_started # Default condition, wait for container start
      kafka: # Add dependency on kafka
        condition: service_healthy # Wait for kafka's healthcheck to pass
    networks:
      - my_network
    restart: unless-stopped

  # Kafka 服务 (Kraft 模式, 单节点)
  kafka:
    image: confluentinc/cp-kafka:latest # 使用 Confluent 提供的 Kafka 镜像
    container_name: kafka
    networks:
      - my_network
    ports:
      # <主机端口>:<容器端口>
      - "9092:9092" # Kafka Broker 对外部(主机或其他非 Docker 网络)暴露的端口
      # - "9093:9093" # Kraft 模式内部 Controller 端口 (我们这里不需要从主机访问)
    environment:
      KAFKA_NODE_ID: 1 # Kraft 模式下每个节点的唯一 ID
      KAFKA_PROCESS_ROLES: 'broker,controller' # 指定节点同时扮演 broker 和 controller 角色
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093' # Kraft Controller 选举配置 (节点 ID@主机名:内部端口)
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093' # Broker 和 Controller 的监听地址
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092' # Broker 广播给客户端(其他容器)的连接地址
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER' # 指定哪个 listener 用于 Controller
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT' # 监听器的安全协议
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT' # Broker 之间通信使用的 listener 名称
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 # 单节点集群，复制因子必须为 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0 # 缩短消费者组初始化时间 (开发用)
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 # 单节点集群配置
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # 单节点集群配置
      # 自动创建 Topic 功能 (开发时方便，生产环境建议关闭)
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true' 

      # --- healthcheck section ---
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"] # Command to run inside container
      interval: 10s # Check every 10 seconds
      timeout: 5s   # Wait max 5 seconds for command to return
      retries: 10   # Try 10 times before marking as unhealthy
    # ------------------------------------

    restart: unless-stopped

volumes: # 定义数据卷，用于数据持久化
  user-mongo-data:
  order-mongo-data:

networks: # 定义网络
  my_network:
    driver: bridge # 使用 Docker 默认的桥接网络驱动